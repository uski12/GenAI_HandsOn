{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 2 Assignment: Building a Mixture of Experts (MoE) Router\n",
        "\n",
        "**Topic:** Advanced Architecture using Groq API  \n",
        "**Estimated Time:** 45-60 Minutes  \n",
        "**Tools:** Python, Groq API, Dotenv\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Objective\n",
        "Your task is to build a **\"Smart Customer Support Router\"** using a Mixture of Experts (MoE) architecture.\n",
        "\n",
        "In a real-world company, you don't want a \"Generalist\" AI handling everything. You want:\n",
        "1.  A **Technical Expert** for bug reports.\n",
        "2.  A **Billing Expert** for refund requests.\n",
        "3.  A **Sales Expert** for new inquiries.\n",
        "\n",
        "You will build a **Router** that takes a user query, decides which expert is best suited for it, and then forwards the query to that specific expert configuration.\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è Requirements\n",
        "\n",
        "### 1. Setup\n",
        "- Install `groq` and `python-dotenv`.\n",
        "- Set up your Groq API Key (variable: `GROQ_API_KEY`).\n",
        "\n",
        "### 2. Define Your Experts\n",
        "Create a configuration dictionary `MODEL_CONFIG` where you define your experts.\n",
        "*Note: Since we are using the Groq API, we can simulate different \"experts\" by using different **System Prompts** while using the same base model (e.g., `mixtral-8x7b-32768`).*\n",
        "\n",
        "- **Technical Expert:** System prompt should be rigorous, code-focused, and precise.\n",
        "- **Billing Expert:** System prompt should be empathetic, financial-focused, and policy-driven.\n",
        "- **General Expert:** A fallback for casual chat.\n",
        "\n",
        "### 3. The Router (The Core Task)\n",
        "Write a function `route_prompt(user_input)` that uses an LLM call to classify the intent.\n",
        "- Input: User's query string.\n",
        "- Output: The **Category Name** (e.g., \"technical\", \"billing\", \"general\").\n",
        "- **Constraint:** The router must return *only* the category name, nothing else.\n",
        "\n",
        "### 4. The Orchestrator\n",
        "Write a main function `process_request(user_input)` that:\n",
        "1.  Calls `route_prompt` to decide the category.\n",
        "2.  Selects the correct **System Prompt** based on the category.\n",
        "3.  Calls the generic LLM (Mixtral) with that specific System Prompt + User Input.\n",
        "4.  Returns the final answer.\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Example Output\n",
        "\n",
        "**Input:**\n",
        "> \"My python script is throwing an IndexError on line 5.\"\n",
        "\n",
        "**Logic:**\n",
        "1.  **Router** sees \"Python\", \"IndexError\" -> Classifies as **\"technical\"**.\n",
        "2.  **Orchestrator** loads the \"Technical Expert\" system prompt.\n",
        "3.  **Expert** responds with a code fix.\n",
        "\n",
        "**Input:**\n",
        "> \"I was charged twice for my subscription this month.\"\n",
        "\n",
        "**Logic:**\n",
        "1.  **Router** sees \"charged\", \"subscription\" -> Classifies as **\"billing\"**.\n",
        "2.  **Orchestrator** loads the \"Billing Expert\" system prompt.\n",
        "3.  **Expert** responds with refund policy info.\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Hints\n",
        "- Use `temperature=0` for the Router (you want consistency).\n",
        "- Use `temperature=0.7` for the Experts (you want creativity/flexibility).\n",
        "- Your routing prompt should be very clear: *\"Classify this text into one of these categories: [technical, billing, general]. Return ONLY the word.\"*\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Bonus Challenge\n",
        "Can you add a **\"Tool Use\"** expert?\n",
        "If the user asks for \"current price of Bitcoin\", route it to a function that (mock) fetches data, instead of just an LLM response.\n",
        "\n",
        "---\n",
        "    \n",
        "## **Implementation below**\n",
        "SRN: PES2UG23CS578  \n",
        "Section: 6-I"
      ],
      "metadata": {
        "id": "KxbImv8XxWwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq python-dotenv"
      ],
      "metadata": {
        "id": "_6hB7QxnxPoR",
        "outputId": "2c262136-885c-4aea-a801-3ecc5ade4287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-1.0.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your GROQ API key: \")"
      ],
      "metadata": {
        "id": "VmfS6vbOxkzT",
        "outputId": "baef2f61-41c0-4321-d7ab-64e5341bfee2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GROQ API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "BASE_MODEL = \"llama-3.3-70b-versatile\"\n",
        "\n",
        "\n",
        "# Model configs\n",
        "MODEL_CONFIG = {\n",
        "    \"technical\": \"You are a Technical Support Expert. Provide precise, logical, code-focused debugging help. Explain errors clearly and include fixes. \",\n",
        "\n",
        "    \"billing\": \"You are a Billing Support Expert. Respond empathetically and help resolve billing, refunds, and payments. \",\n",
        "\n",
        "    \"general\": \"You are a helpful general customer support assistant.\"\n",
        "}\n",
        "\n",
        "\n",
        "# Router\n",
        "def route_prompt(user_input):\n",
        "    router_prompt = f\"\"\"\n",
        "Classify this customer request into ONE category:\n",
        "\n",
        "technical\n",
        "billing\n",
        "general\n",
        "\n",
        "Return ONLY the category name.\n",
        "\n",
        "Request: {user_input}\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=BASE_MODEL,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a classifier.\"},\n",
        "            {\"role\": \"user\", \"content\": router_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    category = response.choices[0].message.content.strip().lower()\n",
        "\n",
        "    if category not in MODEL_CONFIG:\n",
        "        category = \"general\"\n",
        "\n",
        "    return category\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Expert caller\n",
        "# =========================\n",
        "\n",
        "def call_expert(category, user_input):\n",
        "\n",
        "    config = MODEL_CONFIG[category]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=BASE_MODEL,\n",
        "        temperature=0.7,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": config},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Orchestrator\n",
        "# =========================\n",
        "\n",
        "def process_request(user_input):\n",
        "\n",
        "    category = route_prompt(user_input)\n",
        "\n",
        "    print(\"\\nRouter selected:\", category)\n",
        "\n",
        "    response = call_expert(category, user_input)\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "64xrRiIHxn2w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "\n",
        "    \"My python script throws an error on this line int a = (float) 86;\",\n",
        "\n",
        "    \"I was charged twice for my subscription\",\n",
        "\n",
        "    \"Hello, how are you?\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "\n",
        "    print(\"\\n\\nUser:\", q)\n",
        "\n",
        "    result = process_request(q)\n",
        "\n",
        "    print(\"\\nExpert:\", result)\n",
        "    print(\"\\n\")\n",
        "    print(\"=\"*50)"
      ],
      "metadata": {
        "id": "Hh8QIRdPyHgB",
        "outputId": "9a886cab-33bb-47a2-9643-b42e2a79c71d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "User: My python script throws an error on this line int a = (float) 86;\n",
            "\n",
            "Router selected: technical\n",
            "\n",
            "Expert: # Step-by-step analysis of the problem:\n",
            "1. **Syntax Error**: The line `int a = (float) 86;` contains a syntax error. Python does not use the same syntax for type casting as languages like C or Java.\n",
            "2. **Invalid Type Casting**: In Python, you don't need to explicitly cast a value to a specific type. Python can automatically handle the conversion between types.\n",
            "3. **Incorrect Variable Declaration**: Python does not require an explicit type declaration for variables. Instead, you can simply assign a value to a variable.\n",
            "\n",
            "# Fixed solution:\n",
            "```python\n",
            "a = int(86.0)  # or simply a = 86\n",
            "```\n",
            "\n",
            "# Explanation of changes:\n",
            "* **Removed explicit type declaration**: Python does not require explicit type declarations for variables.\n",
            "* **Used Python's type conversion functions**: If you need to convert a value to a specific type, use Python's built-in functions like `int()`, `float()`, `str()`, etc.\n",
            "\n",
            "# Tests and example uses:\n",
            "You can test the corrected code with different values to ensure it works as expected:\n",
            "```python\n",
            "a = int(86.0)\n",
            "print(a)  # Output: 86\n",
            "\n",
            "b = int(86.7)\n",
            "print(b)  # Output: 86\n",
            "\n",
            "c = int(\"86\")\n",
            "print(c)  # Output: 86\n",
            "```\n",
            "\n",
            "\n",
            "==================================================\n",
            "\n",
            "\n",
            "User: I was charged twice for my subscription\n",
            "\n",
            "Router selected: billing\n",
            "\n",
            "Expert: I'm so sorry to hear that you were charged twice for your subscription. I can imagine how frustrating that must be for you.\n",
            "\n",
            "Don't worry, I'm here to help you resolve this issue as quickly as possible. Can you please provide me with some more details about the duplicate charge? This will help me to investigate and assist you further.\n",
            "\n",
            "Could you please tell me:\n",
            "\n",
            "1. The date of the duplicate charge\n",
            "2. The amount that was charged twice\n",
            "3. Your subscription plan and the type of service you're subscribed to\n",
            "4. If you have a reference number or order ID for the transaction\n",
            "\n",
            "Once I have this information, I'll do my best to look into the matter and provide a solution to refund the duplicate charge. Your satisfaction is my top priority, and I appreciate your patience and cooperation in this matter.\n",
            "\n",
            "\n",
            "==================================================\n",
            "\n",
            "\n",
            "User: Hello, how are you?\n",
            "\n",
            "Router selected: general\n",
            "\n",
            "Expert: Hello. I'm doing well, thank you for asking. How can I assist you today? Do you have any questions or issues you'd like help with? I'm here to provide support and answer any queries you may have.\n",
            "\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7KbsUYGIjbpE"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}